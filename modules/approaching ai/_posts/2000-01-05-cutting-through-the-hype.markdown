---
title: Cutting Through the Hype
---

# Cutting Through the Hype

<br>
Media outlets continue to write stories about AI -- and today especially, deep neural networks -- that are grotesquely sensationalized, often to the point of <b>anthropomorphizing</b> or attributing human-like characteristics to computer programs.

<br>
For example, consider the headline <i>Google Supercomputer Gives Birth To Its Own AI Child.</i> (This is a real headline; if you <a href='https://www.google.com/search?q=Google+Supercomputer+Gives+Birth+To+Its+Own+AI+Child'>Google it</a> you'll find dozens of articles with similar headlines.)

<center><img src="https://aihigh.github.io/assets/images/google-supercomputer-gives-birth-to-its-own-ai-child.png" width="80%"></img></center>

<br>
The way the headline is phrased, it would lead you to think that Google researchers built a futuristic computer, and that computer somehow gave birth to a human-like child that is composed of circuits rather than flesh and blood. But this is simply not true.

<br>
Rather, Google researchers built a model to predict good <b>hyperparameters</b> for training a different model to perform a specific task. Hyperparameters are settings which control some aspect of the training process, such as how often to perform training computations and how much to adjust the network connectivity based on the results of a training repetition. Usually, these settings are chosen by researchers training a model, but in the case of this article, researchers built another model to predict which training settings would lead to good performance on a specific task.

<br>
In some analogy, then, the model being trained to perform a task is like a “child,” and the model predicting good hyperparameters for the child model's training is like a “parent.” But did this parent model give birth to the child model in a human-like way? Does the child model resemble a human-like child? The answer to both of these questions is a resounding no. 

<br>
If someone didn't realize that the headline <i>Google Supercomputer Gives Birth To Its Own “AI Child”</i> was just a loose analogy, then they might begin to develop ridiculous opinions about AI based on the false assumption that computers can literally give birth to AI children resembling human children. For example, an uninformed pessimistic reader might argue that we need to stop AI research because a growing population of AI children will pose a threat to the human population. Or, an uninformed optimistic reader might argue that we must rush to pass laws supporting the equality of AI children, lest they be discriminated against. Both arguments are irrelevant to the present state of AI.

<br>
The takeaway of this discussion is that when you read about AI in the news, you should be skeptical of titles which appear sensationalized or anthropomorphized. If some statement about the field of AI is too good (or too bad) to be true, then it probably isn't true in a literal sense. This will become increasingly apparent as you learn more about the technical underpinnings of AI.
